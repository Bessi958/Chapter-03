{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Data Structures Effectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Competence as a Data Scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a lot of data structures to choose from \n",
    "    - you have to choose the best ones possible for the dataset you are currently working on \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance of using the right data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data structure is optimized for that use case\n",
    "- useful methods are associated with it\n",
    "\n",
    "-> so if you choose the correct data structure:\n",
    "- code performs better and is also easier to use\n",
    "- code is more predictable and easier to understand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Typical data structures for Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python lists, tuples, dictionaries, sets\n",
    "- NumPy arrays\n",
    "- pandas DataFrames \n",
    "\n",
    "- many more data structures more suitable for data engineering than data science\n",
    "    - recommended book for more information: A Common-Sense Guide to Data Structures and Algorithms\n",
    "in Python by Jay Wengrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Native Python Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Lists**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python allocates a continuous chunk of memory according to the size of the list with one element of a list in the next door memory location to the next element.\n",
    "\n",
    "This has important implications: it’s very easy to look up an element in a list. \n",
    "\n",
    "The Python interpreter knows the memory location of the start of the list, then if you’re looking up the fifth element in the list, it simply retrieves the element that’s in the fifth memory location from the start.\n",
    "\n",
    "Each time you add an element to a list it takes up extra space in memory. \n",
    "\n",
    "Python allocates some extra space beyond the length of the original list, but once this space is full, the entire list needs to be copied into a new memory location with more consecutive space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- command: %% timeit\n",
    "\n",
    "- List lookups (using indexing): O(1) -> runtime independent of size\n",
    "\n",
    "- Appending at the end of a list: O(1) + overhead (copying and moving to a new memory location)\n",
    "\n",
    "- Inserting & Deleting (in the middle): O(n) -> runtime increases linearly with size\n",
    "    - each element after the newly inserted one must move to the next memory location  \n",
    "\n",
    "- Adding elements to start and end of a list: use deque data structure from 'collections' module \n",
    "\n",
    "- Search list (iterating through): O(n)\n",
    "    - frequently searching through the list -> choose other data structure\n",
    "\n",
    "- Adding elements up to a specific length: <list>.append() not efficient\n",
    "    - better options: \n",
    "        - list comprehension\n",
    "        - create a list of 0s with a length according to the number of elemnts you want to add later on\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tuples**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuples in Python are also an array, but they have a static size. They are immutable.\n",
    "\n",
    "Tuples are useful when you have only a few items you want to store in a data structure, and those items are not going to change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cached in Python runtime \n",
    "    - not stored in memory "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lookups: O(1) -> faster than lists \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dictionaries**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionaries are based on key and value pairs.\n",
    "\n",
    "This means there are pairs of data elements that have some link between them, for example, the name of a person and their street address. \n",
    "\n",
    "Dictionaries are best for data that has no inherent ordering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hash tables:\n",
    "\n",
    "- A hash function maps keys to an integer that is the relevant index in the list of values.\n",
    "\n",
    "- A dictionary key needs to be a hashable type such as a string, an integer, or a float. A Python list can’t be hashed.\n",
    "\n",
    "- The hash function must return the same integer every time it is applied to the same key. Keys in the dictionary also must be unique so that it’s possible to return the correct value.\n",
    "\n",
    "**problem**: large memory footprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- search for a value using the corresponding key: O(1)\n",
    "\n",
    "- inserting, updating, deleting: O(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sets are used for data with no inherent order.\n",
    "\n",
    "Sets are implemented in Python using a hash table, similar to dictionaries. However, instead of key and value pairs, they just have a set of unique keys. \n",
    "\n",
    "This means that all the elements in a set must be unique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- inserting, updating, deleting, lookups: O(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- counting number of unique element in a list (efficiently):\n",
    "\n",
    "    - (1) convert list to set\n",
    "    - (2) Look up length \n",
    "\n",
    "- if you repeatedly want to check whether items are present in a list -> convert list to set before lookup\n",
    "    - if checks don't need to be performed often -> converting takes too much time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **NumPy Arrays**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy core data structure: the ndarray or n-dimensional array\n",
    "\n",
    "It's best to use with multidimensional data.\n",
    "\n",
    "It is possible to make a multidimensional data structure from nested Python lists, but\n",
    "it quickly becomes difficult to perform calculations on them. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look up the values in the first column of a 2D list\n",
    "\n",
    "python_2d_list =[[1, 3, 5], [2, 4, 6], [7, 9, 11]]\n",
    "\n",
    "first_column = [python_2d_list[i][0] for i in range(len(python_2d_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look up the values in the first column of a 2D numpy array\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np_2d_array = np.array([[1, 3, 5], [2, 4, 6], [7, 9, 11]])\n",
    "\n",
    "first_column = np_2d_array[:, 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy Arrays allow data of only a *single* type. (The type of the elements in a NumPy array is stored with it and can be looked up using the .dtype attribute)\n",
    "\n",
    "This might seem like a limitation, but it actually has huge performance benefits. \n",
    "\n",
    "Knowing that every element in a NumPy array is the same type leads to large performance gains, in particular for what’s known as vectorized calculations (operating on every element in an array at once, instead of iterating through every element).\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of mixed data types\n",
    "\n",
    "mixed_type_list = [\"one\", 2, 3.14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one' '2' '3.14']\n"
     ]
    }
   ],
   "source": [
    "# numpy array of mixed data types (all elements will be converted to strings)\n",
    "\n",
    "mixed_type_array = np.array([\"one\", 2, 3.14])\n",
    "\n",
    "print(mixed_type_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting elements from a list creates a copy, while in NumPy, it creates a view, making changes affect the original array and improving performance (faster and more memory efficient)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy arrays are created as a continuous block of memory.\n",
    "\n",
    "Unlike a regular Python list, when NumPy allocates space for an array, it doesn’t allow any extra room. \n",
    "\n",
    "So if you append more elements to a NumPy array the entire array needs to be moved to a new memory location every\n",
    "time.\n",
    "\n",
    "It’s definitely worthwhile to initialize your array with the correct amount of space, and an easy way to do this is to use np.zeros, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_to_fill = np.zeros(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can look up the number of bytes the arrays takes up by using the .nbytes attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_int_array = np.random.randint(1, 100_000, 100_000)\n",
    "\n",
    "random_int_array.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_int_array.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save a lot of memory space you can reduce the (bit) range allowed by different dtypes. \n",
    "\n",
    "Example: dtype('int32'), if you don't need a range this big you can change the dtype to 'int16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can convert your array by using the .astype method\n",
    "\n",
    "random_int_array_32 = random_int_array.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You also can do this out of the box by specifying the dtype when you initialize the array\n",
    "\n",
    "small_array = np.array([1, 3, 5], dtype=np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- open-source parallel computing libary \n",
    "\n",
    "- it's worth using only if you need a performance boost \n",
    "    - provides similar interface as NumPy arrays but adds more complexity\n",
    "    - can be used for larger memory arrays or for parallelized computations\n",
    "    - arrays are divided into chunks (no need to load whole array into memory)\n",
    "    - computations on chunks can be run parallel -> combining the results in the end\n",
    "    - allows to run computations on multiple cores at once on your laptop and on distributed systems (clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arrays in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data storage in ML (whether that's categorical, image, text data): \n",
    "    - matrices (two-dimensional arrays) \n",
    "    - tensors (higher-dimension arrays)\n",
    "\n",
    "- two most popular training frameworks: \n",
    "    - TensorFlow\n",
    "    - PyTorch\n",
    "    \n",
    "    -> easy convertion of NumPy arrays for either of those frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **pandas DataFrames**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> most popular libary for Data Science\n",
    "- key libary for manipulating and analyzing data\n",
    "- originally build on top of NumPy \n",
    "    - many principles also apply to pandas DataFrames, but there are features specific to pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- two key data structures:\n",
    "    - Series: \n",
    "        - one-dimensional NumPy array with an index \n",
    "        - lookup possible by index or location \n",
    "        - created as a continuous block of memory just as NumPy arrays\n",
    "        -> same performance considerations apply\n",
    "    - DataFrames:\n",
    "        - two-dimensional arrangement of pandas Series structures with a column index\n",
    "        - each column can be a different type\n",
    "        - 'object' column type: can mix data of different types within a Series\n",
    "\n",
    "- more functions to handle missing data than NumPy\n",
    "\n",
    "- useful for two-dimensional tabular data with row and column information or for spreadsheet-style data\n",
    "- can be used similarly to database tables \n",
    "    - option to join or query data \n",
    "    - works best when setting up a full database is not worth it \n",
    "\n",
    "- pandas has specialized functions for working with time series "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- many vectorized operations (apply calculations at once)\n",
    "\n",
    "    - always use when available (best performance)\n",
    "    - special for pandas: vectorized string operations \n",
    "    \n",
    "        -> e.g. `df['column_name'].str.lower()` faster than regular python `.lower()` method\n",
    "\n",
    "- use build-in functions (if not available: use `apply` with any function you define)\n",
    "\n",
    "- *problem*: dataFrame larger than computers memory \n",
    "    \n",
    "    -> ways to solve: \n",
    "\n",
    "    - only load columns you want to work on\n",
    "\n",
    "        `df = pd.read_csv(file_path, usecols = ['column_1', 'column_2'])`\n",
    "    \n",
    "    - create an iterator to work on only a subset of rows (chunksize) at a time \n",
    "        \n",
    "        `chunks = pd.read_csv(file_path, chunksize = <chunksize>)`\n",
    "\n",
    "    - Dask libary\n",
    "\n",
    "    - Polars libary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **References**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"Python in a Nutshell\" \n",
    "    by Alex Martelli, Anna Martelli Ravenscroft, Steve Holden, and Paul McGuire (O’Reilly, 2023) for a good overview of Python data structures.\n",
    "\n",
    "- \"Python for Data Analysis\"\n",
    "    by Wes McKinney (O’Reilly, 2021) for more details on NumPy arrays and pandas DataFrames.\n",
    "\n",
    "- \"High Performance Python\"\n",
    "    by Micha Gorelick and Ian Osvald (O’Reilly, 2020) for much more detail on optimizing Python performance.\n",
    "\n",
    "- \"Scaling Python with Dask\" \n",
    "    by Holden Karau and Mika Kimmins (O’Reilly 2023) for more on how to use Dask for data science.\n",
    "    \n",
    "- Data science articles on the [Python Speed website.](https://pythonspeed.com/datascience)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
